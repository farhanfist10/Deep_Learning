{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_skills(text):\n",
    "    doc = nlp(text)\n",
    "    skills = [ent.text for ent in doc.ents if ent.label_ == \"SKILL\"]\n",
    "    return skills\n",
    "\n",
    "job_description = \"Looking for a data scientist with experience in Python, machine learning, and NLP.\"\n",
    "skills = extract_skills(job_description)\n",
    "print(skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'machine learning']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "skills_list = [\"Python\", \"Java\", \"machine learning\"]\n",
    "patterns = [nlp(skill.lower()) for skill in skills_list]\n",
    "matcher.add(\"SKILLS\", patterns)\n",
    "\n",
    "def extract_skills(text):\n",
    "    doc = nlp(text.lower())\n",
    "    matches = matcher(doc)\n",
    "    skills = [doc[start:end].text for match_id, start, end in matches]\n",
    "    return skills\n",
    "\n",
    "\n",
    "text = \"I have experience with python, java, and machine learning.\"\n",
    "print(extract_skills(text))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the content from the resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farhan Akthar K\n",
      "farhanakthar2003@gmail.com\n",
      "Chennai,India\n",
      "farhanfist109710580532\n",
      "Farhan Akthar.K\n",
      "Education\n",
      "present\n",
      "Chennai, IndiaB.Tech -Information Technology(CGPA-8.43)\n",
      "St Joseph's College Of Engineering-\u0000\u0000\u0000\u0000\n",
      "2021\n",
      "chennai, IndiaHigher Secondary Education(94.17%)\n",
      "Ramakrishna Mission Matric.Hr.Secondary School\n",
      "2019\n",
      "Chennai, IndiaSecondary Education(93.43%)\n",
      "Ramakrishna Mission Matric.Hr.Secondary School\n",
      "Technical Skills\n",
      "Python\n",
      "HTML,CSS,JS\n",
      "Node, Express, MongoDB\n",
      "C++Java\n",
      "React\n",
      "SQL (MySQL, SQLite)\n",
      "PowerBI\n",
      "Projects\n",
      "Dynamic Chat Application | React, Mongo DB, Node.js, Express.js, Socket.io.\n",
      "•Implemented a responsive front-end using React, enhancing user experience and ensuring real-time \n",
      "messaging functionality.\n",
      "•Developed and optimized RESTful APIs with Express.js and Node.js, improving application performance \n",
      "and data handling.\n",
      "•Utilized MongoDB for scalable data storage, integrating user authentication and security features to protect \n",
      "user data and privacy.\n",
      "Book Store Management | React, Mongo DB, Node.js, Express.js.\n",
      "•Developed a book management application using the MERN stack, allowing users to perform CRUD \n",
      "operations such as adding, updating, viewing, and deleting books.\n",
      "•Implemented a responsive front-end using React, enhancing user experience with features like search and \n",
      "filter options.\n",
      "•Developed RESTful APIs with Express.js and Node.js for efficient data handling and real-time updates. \n",
      "Utilized MongoDB for robust and scalable data storage, ensuring data integrity and security.\n",
      "Workout Application | React, Mongo DB, Node.js, Express.js.\n",
      "•Developed a workout management application using the MERN stack, enabling user authentication with \n",
      "JSON Web Tokens (JWT) and allowing registered users to perform CRUD operations on workouts.\n",
      "•Implemented secure user authentication and authorization using JSON Web Tokens (JWT), ensuring data \n",
      "privacy and secure access.\n",
      "•Built robust RESTful APIs with Express.js and Node.js, facilitating efficient data handling and seamless \n",
      "interaction with MongoDB for scalable data storage.Contact-app Manager | Mongo DB, Node.js ,Express.js.\n",
      "•Designed and implemented a RESTful API using Node.js and Express.js for efficient data handling and \n",
      "CRUD operations.\n",
      "•Utilized MongoDB for robust and scalable data storage, ensuring efficient management of user details.\n",
      "•Integrated user authentication to enhance data security and provide personalized user experiences.\n",
      "House Price Prediction | Python, Flask, Scikit-learn, Pandas, NumPy, HTML/CSS\n",
      "•Utilized state-of-the-art machine learning techniques and algorithms, including linear regression, decision \n",
      "trees, and random forests, to achieve high prediction accuracy.\n",
      "•Implemented a user-friendly web interface using Flask, enabling users to input data and view predicted \n",
      "house prices.\n",
      "•Conducted data preprocessing and feature engineering using Pandas and NumPy, optimizing the model's \n",
      "performance and reliability.\n",
      "Food Chat Bot | Dialogflow, Python, FastAPI, MySQL.\n",
      "•Crafted a chatbot solution using Dialogflow, enabling intuitive and natural interactions with customers.\n",
      "•Engineered a robust backend system with Python and FastAPI, ensuring reliable performance and \n",
      "scalability.\n",
      "•Utilized MySQL for effective handling and organization of order data, streamlining restaurant operations \n",
      "and enhancing customer experience.\n",
      "To-Do-List | React\n",
      "•Created a robust To-Do List application using the React library, enabling efficient task management.\n",
      "•Implemented essential features such as task addition, editing, deletion, categorization, and priority settings.\n",
      "Courses & Certificates\n",
      "Complete Web Development Bootcamp\n",
      "Udemy | Instructor-Dr. Angela Yu\n",
      "Machine Learning & AI\n",
      "Prepinsta Technologies PVT.LTD\n",
      "Data Science\n",
      "PrepInsta Technologies PVT.LTD\n",
      "Business English Certification(BEC) -Preliminary\n",
      "Achievements\n",
      "POSTEROLIC-Designing Event 2023\n",
      "Runner\n",
      "Smart India Hackathon-2022\n",
      "Participation\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "resume_text = extract_text_from_pdf(\"res_ume.pdf\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farhan Akthar K farhanakthar2003 @ gmail.com Chennai , India Farhan Akthar.K Education present Chennai , IndiaB.Tech -Information Technology ( CGPA-8.43 ) St Joseph 's College Of Engineering- 2021 Chennai , India Higher Secondary Education ( 94.17 % ) Ramakrishna Mission Matric.Hr.Secondary School 2019 Chennai , IndiaSecondary Education ( 93.43 % ) Ramakrishna Mission Matric.Hr.Secondary School Technical Skills Python , HTML , CSS , JS , Node , Express , MongoDB , C++ , Java , React , SQL , Machine Learning , NLP ( MySQL , SQLite ) , PowerBI Projects Dynamic Chat Application | React , Mongo DB , Node.js , Express.js , Socket.io .\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fakthar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fakthar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "processed_text11 = preprocess_text(resume_text)\n",
    "print(processed_text11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(processed_text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_list = [\n",
    "    \"Python\", \"HTML\", \"CSS\", \"JavaScript\", \"Node\", \"Express\", \"MongoDB\",\n",
    "    \"C++\", \"Java\", \"React\", \"SQL\", \"MySQL\", \"SQLite\", \"PowerBI\", \"Flask\",\n",
    "    \"Scikit-learn\", \"Pandas\", \"NumPy\", \"FastAPI\", \"Dialogflow\",\"NLP\",\"Machine Learning\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java, NLP, SQL, SQLite, React, PowerBI, Express, Python, CSS, Node, C++, MongoDB, HTML, MySQL\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_skills(resume_text, skills_list):\n",
    "    # Convert skills_list to lowercase for case-insensitive matching\n",
    "    normalized_skills = [skill.lower() for skill in skills_list]\n",
    "    \n",
    "    # Initialize an empty set to store extracted skills\n",
    "    extracted_skills = set()\n",
    "\n",
    "    # Tokenize resume text into words\n",
    "    tokens = resume_text.split()\n",
    "\n",
    "    # Iterate over tokens and check against skills_list\n",
    "    for token in tokens:\n",
    "        normalized_token = token.lower().strip(\",.()•\")  # Normalize token for comparison\n",
    "        if normalized_token in normalized_skills:\n",
    "            extracted_skills.add(token.strip(\",.()•\"))\n",
    "\n",
    "    return extracted_skills\n",
    "\n",
    "# Example resume text (abbreviated for brevity)\n",
    "resume_text = \"\"\"\n",
    "Farhan Akthar K farhanakthar2003@gmail.com Chennai, India\n",
    "Farhan Akthar.K Education present Chennai, IndiaB.Tech -Information Technology (CGPA-8.43) \n",
    "St Joseph's College Of Engineering- 2021 Chennai, India\n",
    "Higher Secondary Education (94.17%) Ramakrishna Mission Matric.Hr.Secondary School 2019 \n",
    "Chennai, IndiaSecondary Education (93.43%) Ramakrishna Mission Matric.Hr.Secondary School \n",
    "Technical Skills Python, HTML, CSS, JS, Node, Express, MongoDB, C++, Java, React, SQL \n",
    "(MySQL, SQLite), PowerBI Projects Dynamic Chat Application | React, Mongo DB, Node.js, Express.js, Socket.io.\n",
    "\"\"\"\n",
    "\n",
    "# Extract skills\n",
    "extracted_skills = extract_skills(processed_text11, skills_list)\n",
    "# my_set = {'Python', 'Java', 'C++', 'HTML', 'CSS'}\n",
    "separator = ', '\n",
    "\n",
    "# Convert set to a single string with elements separated by ', '\n",
    "extracted_skills1 = separator.join(extracted_skills)\n",
    "\n",
    "print(extracted_skills1)\n",
    "# print(f\"Extracted Skills: {extracted_skills}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted Skills: Python, HTML, CSS, Node, Express, MongoDB, C++, Java, React, SQL, NLP, MySQL, SQLite, PowerBI, React\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_skills(resume_text, skills_list):\n",
    "    # Convert skills_list to lowercase for case-insensitive matching\n",
    "    normalized_skills = [skill.lower() for skill in skills_list]\n",
    "    \n",
    "    # Initialize an empty list to store extracted skills\n",
    "    extracted_skills = []\n",
    "\n",
    "    # Tokenize resume text into words\n",
    "    tokens = resume_text.split()\n",
    "\n",
    "    # Iterate over tokens and check against skills_list\n",
    "    for token in tokens:\n",
    "        normalized_token = token.lower().strip(\",.()•\")  # Normalize token for comparison\n",
    "        if normalized_token in normalized_skills:\n",
    "            extracted_skills.append(token.strip(\",.()•\"))\n",
    "\n",
    "    # Join the extracted skills into a single string separated by commas\n",
    "    skills_string = \", \".join(extracted_skills)\n",
    "    \n",
    "    return skills_string\n",
    "\n",
    "# Example resume text (abbreviated for brevity)\n",
    "resume_text = \"\"\"\n",
    "Farhan Akthar K farhanakthar2003@gmail.com Chennai, India\n",
    "Farhan Akthar.K Education present Chennai, IndiaB.Tech -Information Technology (CGPA-8.43) \n",
    "St Joseph's College Of Engineering- 2021 Chennai, India\n",
    "Higher Secondary Education (94.17%) Ramakrishna Mission Matric.Hr.Secondary School 2019 \n",
    "Chennai, IndiaSecondary Education (93.43%) Ramakrishna Mission Matric.Hr.Secondary School \n",
    "Technical Skills Python, HTML, CSS, JS, Node, Express, MongoDB, C++, Java, React, SQL ,Machine Learning,NLP\n",
    "(MySQL, SQLite), PowerBI Projects Dynamic Chat Application | React, Mongo DB, Node.js, Express.js, Socket.io.\n",
    "\"\"\"\n",
    "\n",
    "# Extract skills as a single string\n",
    "extracted_skills_string = extract_skills(processed_text11, skills_list)\n",
    "print(f\"Extracted Skills: {extracted_skills_string}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python , HTML , CSS , Node , Express , MongoDB , C++ , Java , React , SQL , NLP , MySQL , SQLite , PowerBI , React\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\fakthar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\fakthar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "processed_text = preprocess_text(extracted_skills_string)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.04692402084245643\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(resume_text, job_description):\n",
    "    documents = [resume_text, job_description]\n",
    "    tfidf = TfidfVectorizer().fit_transform(documents)\n",
    "    cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "# resume = \"Experienced in Python, machine learning, and deep learning.\"\n",
    "job_description = \"Looking for a data scientist with experience in Python.\"\n",
    "similarity_score = calculate_similarity(processed_text, job_description)\n",
    "print(f\"Similarity Score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.18068688270171662\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Predefined list of skills to match against\n",
    "skills_list = [\n",
    "    \"Python\", \"HTML\", \"CSS\", \"JavaScript\", \"Node\", \"Express\", \"MongoDB\",\n",
    "    \"C++\", \"Java\", \"React\", \"SQL\", \"MySQL\", \"SQLite\", \"PowerBI\", \"Flask\",\n",
    "    \"Scikit-learn\", \"Pandas\", \"NumPy\", \"FastAPI\", \"Dialogflow\", \"NLP\"\n",
    "]\n",
    "\n",
    "def extract_skills_as_string(text, skills_list):\n",
    "    normalized_skills = [skill.lower() for skill in skills_list]\n",
    "    extracted_skills = []\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        normalized_token = token.lower().strip(\",.()•\")\n",
    "        if normalized_token in normalized_skills:\n",
    "            extracted_skills.append(token.strip(\",.()•\"))\n",
    "    skills_string = \", \".join(extracted_skills)\n",
    "    return skills_string\n",
    "\n",
    "def calculate_similarity(skills_from_resume, skills_from_job_description):\n",
    "    documents = [skills_from_resume, skills_from_job_description]\n",
    "    tfidf = TfidfVectorizer().fit_transform(documents)\n",
    "    cosine_sim = cosine_similarity(tfidf[0:1], tfidf[1:2])\n",
    "    return cosine_sim[0][0]\n",
    "\n",
    "# Example resume skills and job description\n",
    "my_skills = \"Python, HTML, CSS, Node, Express, MongoDB, C++, Java, React, SQL, NLP, MySQL, SQLite, PowerBI, React\"\n",
    "job_description = \"Looking for a data scientist with experience in Python.\"\n",
    "\n",
    "# Extract skills from job description\n",
    "job_description_skills = extract_skills_as_string(job_description, skills_list)\n",
    "\n",
    "# Calculate similarity\n",
    "similarity_score = calculate_similarity(my_skills, job_description_skills)\n",
    "print(f\"Similarity Score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Python, HTML, CSS, Node, Express, MongoDB, C++, Java, React, SQL, NLP, MySQL, SQLite, PowerBI, React'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_skills_string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "def extract_skills_as_list(text, skills_list):\n",
    "    normalized_skills = [skill.lower() for skill in skills_list]\n",
    "    extracted_skills = []\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        normalized_token = token.lower().strip(\",.()•\")\n",
    "        if normalized_token in normalized_skills:\n",
    "            extracted_skills.append(token.strip(\",.()•\"))\n",
    "    return extracted_skills\n",
    "\n",
    "def calculate_manual_similarity(resume_skills, job_skills):\n",
    "    resume_skills_set = set(resume_skills)\n",
    "    job_skills_set = set(job_skills)\n",
    "    intersection = resume_skills_set.intersection(job_skills_set)\n",
    "    if len(job_skills_set) == 0:\n",
    "        return 0.0\n",
    "    similarity_score = len(intersection) / len(job_skills_set)\n",
    "    return similarity_score\n",
    "\n",
    "# Example resume skills and job description\n",
    "resume_text = \"\"\"\n",
    "Farhan Akthar K farhanakthar2003@gmail.com Chennai, India\n",
    "Farhan Akthar.K Education present Chennai, IndiaB.Tech -Information Technology (CGPA-8.43) \n",
    "St Joseph's College Of Engineering- 2021 Chennai, India\n",
    "Higher Secondary Education (94.17%) Ramakrishna Mission Matric.Hr.Secondary School 2019 \n",
    "Chennai, IndiaSecondary Education (93.43%) Ramakrishna Mission Matric.Hr.Secondary School \n",
    "Technical Skills Python, HTML, CSS, JS, Node, Express, MongoDB, C++, Java, React, SQL \n",
    "(MySQL, SQLite), PowerBI Projects Dynamic Chat Application | React, Mongo DB, Node.js, Express.js, Socket.io.\n",
    "\"\"\"\n",
    "job_description = \"Looking for a data scientist with experience in Springboot.\"\n",
    "\n",
    "# Predefined list of skills to match against\n",
    "skills_list = [\n",
    "    \"Python\", \"HTML\", \"CSS\", \"JavaScript\", \"Node\", \"Express\", \"MongoDB\",\n",
    "    \"C++\", \"Java\", \"React\", \"SQL\", \"MySQL\", \"SQLite\", \"PowerBI\", \"Flask\",\n",
    "    \"Scikit-learn\", \"Pandas\", \"NumPy\", \"FastAPI\", \"Dialogflow\", \"NLP\"\n",
    "]\n",
    "\n",
    "# Extract skills from resume and job description\n",
    "resume_skills = extract_skills_as_list(resume_text, skills_list)\n",
    "job_description_skills = extract_skills_as_list(job_description, skills_list)\n",
    "\n",
    "# Calculate manual similarity\n",
    "similarity_score = calculate_manual_similarity(resume_skills, job_description_skills)\n",
    "print(f\"Similarity Score: {similarity_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
