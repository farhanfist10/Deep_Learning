{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python', 'java', 'machine learning']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "\n",
    "skills_list = [\"Python\", \"Java\", \"machine learning\"]\n",
    "patterns = [nlp(skill.lower()) for skill in skills_list]\n",
    "matcher.add(\"SKILLS\", patterns)\n",
    "\n",
    "def extract_skills(text):\n",
    "    doc = nlp(text.lower())\n",
    "    matches = matcher(doc)\n",
    "    skills = [doc[start:end].text for match_id, start, end in matches]\n",
    "    return skills\n",
    "\n",
    "\n",
    "skill_text = \"I have experience with python, java, and machine learning.\"\n",
    "print(extract_skills(skill_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Farhan Akthar K\n",
      "farhanakthar2003@gmail.com\n",
      "Chennai,India\n",
      "farhanfist109710580532\n",
      "Farhan Akthar.K\n",
      "Education\n",
      "present\n",
      "Chennai, IndiaB.Tech -Information Technology(CGPA-8.43)\n",
      "St Joseph's College Of Engineering-\u0000\u0000\u0000\u0000\n",
      "2021\n",
      "chennai, IndiaHigher Secondary Education(94.17%)\n",
      "Ramakrishna Mission Matric.Hr.Secondary School\n",
      "2019\n",
      "Chennai, IndiaSecondary Education(93.43%)\n",
      "Ramakrishna Mission Matric.Hr.Secondary School\n",
      "Technical Skills\n",
      "Python\n",
      "HTML,CSS,JS\n",
      "Node, Express, MongoDB\n",
      "C++Java\n",
      "React\n",
      "SQL (MySQL, SQLite)\n",
      "PowerBI\n",
      "Projects\n",
      "Dynamic Chat Application | React, Mongo DB, Node.js, Express.js, Socket.io.\n",
      "•Implemented a responsive front-end using React, enhancing user experience and ensuring real-time \n",
      "messaging functionality.\n",
      "•Developed and optimized RESTful APIs with Express.js and Node.js, improving application performance \n",
      "and data handling.\n",
      "•Utilized MongoDB for scalable data storage, integrating user authentication and security features to protect \n",
      "user data and privacy.\n",
      "Book Store Management | React, Mongo DB, Node.js, Express.js.\n",
      "•Developed a book management application using the MERN stack, allowing users to perform CRUD \n",
      "operations such as adding, updating, viewing, and deleting books.\n",
      "•Implemented a responsive front-end using React, enhancing user experience with features like search and \n",
      "filter options.\n",
      "•Developed RESTful APIs with Express.js and Node.js for efficient data handling and real-time updates. \n",
      "Utilized MongoDB for robust and scalable data storage, ensuring data integrity and security.\n",
      "Workout Application | React, Mongo DB, Node.js, Express.js.\n",
      "•Developed a workout management application using the MERN stack, enabling user authentication with \n",
      "JSON Web Tokens (JWT) and allowing registered users to perform CRUD operations on workouts.\n",
      "•Implemented secure user authentication and authorization using JSON Web Tokens (JWT), ensuring data \n",
      "privacy and secure access.\n",
      "•Built robust RESTful APIs with Express.js and Node.js, facilitating efficient data handling and seamless \n",
      "interaction with MongoDB for scalable data storage.Contact-app Manager | Mongo DB, Node.js ,Express.js.\n",
      "•Designed and implemented a RESTful API using Node.js and Express.js for efficient data handling and \n",
      "CRUD operations.\n",
      "•Utilized MongoDB for robust and scalable data storage, ensuring efficient management of user details.\n",
      "•Integrated user authentication to enhance data security and provide personalized user experiences.\n",
      "House Price Prediction | Python, Flask, Scikit-learn, Pandas, NumPy, HTML/CSS\n",
      "•Utilized state-of-the-art machine learning techniques and algorithms, including linear regression, decision \n",
      "trees, and random forests, to achieve high prediction accuracy.\n",
      "•Implemented a user-friendly web interface using Flask, enabling users to input data and view predicted \n",
      "house prices.\n",
      "•Conducted data preprocessing and feature engineering using Pandas and NumPy, optimizing the model's \n",
      "performance and reliability.\n",
      "Food Chat Bot | Dialogflow, Python, FastAPI, MySQL.\n",
      "•Crafted a chatbot solution using Dialogflow, enabling intuitive and natural interactions with customers.\n",
      "•Engineered a robust backend system with Python and FastAPI, ensuring reliable performance and \n",
      "scalability.\n",
      "•Utilized MySQL for effective handling and organization of order data, streamlining restaurant operations \n",
      "and enhancing customer experience.\n",
      "To-Do-List | React\n",
      "•Created a robust To-Do List application using the React library, enabling efficient task management.\n",
      "•Implemented essential features such as task addition, editing, deletion, categorization, and priority settings.\n",
      "Courses & Certificates\n",
      "Complete Web Development Bootcamp\n",
      "Udemy | Instructor-Dr. Angela Yu\n",
      "Machine Learning & AI\n",
      "Prepinsta Technologies PVT.LTD\n",
      "Data Science\n",
      "PrepInsta Technologies PVT.LTD\n",
      "Business English Certification(BEC) -Preliminary\n",
      "Achievements\n",
      "POSTEROLIC-Designing Event 2023\n",
      "Runner\n",
      "Smart India Hackathon-2022\n",
      "Participation\n"
     ]
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    reader = PdfReader(pdf_path)\n",
    "    text = \"\"\n",
    "    for page in reader.pages:\n",
    "        text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "resume_text = extract_text_from_pdf(\"res_ume.pdf\")\n",
    "print(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(resume_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_list = [\n",
    "    \"Python\", \"HTML\", \"CSS\", \"JavaScript\", \"Node\", \"Express\", \"MongoDB\",\n",
    "    \"C++\", \"Java\", \"React\", \"SQL\", \"MySQL\", \"SQLite\", \"PowerBI\", \"Flask\",\n",
    "    \"Scikit-learn\", \"Pandas\", \"NumPy\", \"FastAPI\", \"Dialogflow\",\"NLP\",\"Machine Learning\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTML, MongoDB, MySQL, Node, Java, SQL, SQLite, Express, PowerBI, Python, C++, CSS, React\n",
      "{'HTML', 'MongoDB', 'MySQL', 'Node', 'Java', 'SQL', 'SQLite', 'Express', 'PowerBI', 'Python', 'C++', 'CSS', 'React'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_skills(resume_text, skills_list):\n",
    "    normalized_skills = [skill.lower() for skill in skills_list]\n",
    "    extracted_skills = set()\n",
    "\n",
    "\n",
    "    tokens = resume_text.split()\n",
    "\n",
    "\n",
    "    for token in tokens:\n",
    "        normalized_token = token.lower().strip(\",.()•\")  \n",
    "        if normalized_token in normalized_skills:\n",
    "            extracted_skills.add(token.strip(\",.()•\"))\n",
    "\n",
    "    return extracted_skills\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "extracted_skills = extract_skills(resume_text, skills_list)\n",
    "\n",
    "separator = ', '\n",
    "\n",
    "\n",
    "extracted_skills1 = separator.join(extracted_skills)\n",
    "\n",
    "print(extracted_skills1)\n",
    "print(extracted_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(extracted_skills1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Score: 0.23076923076923078\n"
     ]
    }
   ],
   "source": [
    "def extract_skills_as_list(text, skills_list):\n",
    "    normalized_skills = [skill.lower() for skill in skills_list]\n",
    "    extracted_skills = []\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "        normalized_token = token.lower().strip(\",.()•\")\n",
    "        if normalized_token in normalized_skills:\n",
    "            extracted_skills.append(token.strip(\",.()•\"))\n",
    "    return extracted_skills\n",
    "\n",
    "def calculate_partial_similarity(resume_skills, job_skills):\n",
    "    resume_skills_set = set(resume_skills)\n",
    "    job_skills_set = set(job_skills)\n",
    "    intersection = resume_skills_set.intersection(job_skills_set)\n",
    "    \n",
    "\n",
    "    if len(job_skills_set) == 0:\n",
    "        return 0.0\n",
    "\n",
    "    total_unique_skills = len(resume_skills_set.union(job_skills_set))\n",
    "    similarity_score = len(intersection) / total_unique_skills\n",
    "    return similarity_score\n",
    "\n",
    "\n",
    "\n",
    "job_description = \"Looking for a data scientist with experience in c++, java, html.\"\n",
    "\n",
    "skills_list = [\n",
    "    \"Python\", \"HTML\", \"CSS\", \"JavaScript\", \"Node\", \"Express\", \"MongoDB\",\n",
    "    \"C++\", \"Java\", \"React\", \"SQL\", \"MySQL\", \"SQLite\", \"PowerBI\", \"Flask\",\n",
    "    \"Scikit-learn\", \"Pandas\", \"NumPy\", \"FastAPI\", \"Dialogflow\", \"NLP\",\n",
    "    \"Spring Boot\",\"C\"\n",
    "]\n",
    "\n",
    "# skills_list = [\n",
    "#     \"Python\", \n",
    "#     \"Spring Boot\",\"C\"\n",
    "# ]\n",
    "\n",
    "resume_skills = extract_skills_as_list(extracted_skills1.lower(), skills_list)\n",
    "job_description_skills = extract_skills_as_list(job_description.lower(), skills_list)\n",
    "\n",
    "similarity_score = calculate_partial_similarity(resume_skills, job_description_skills)\n",
    "print(f\"Similarity Score: {similarity_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
